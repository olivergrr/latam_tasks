{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee82243c-fcbb-4cf8-bbc0-fae7eab78224",
   "metadata": {},
   "source": [
    "# Challenge Data Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b29ba-6c1e-471e-a20b-2b31b77bfdf6",
   "metadata": {},
   "source": [
    "Este Notebook contiene las soluciones para resolver tres problemas usando la libreria de pyspark, consta de 4 secciones:\n",
    "- Inicialización, en donde se importa las librerias, constantes y funciones que se usan en el resto del código\n",
    "- Una sección por cada uno de los tres problemas del reto. Cada solución contiene la descripción, las soluciones con dos versiones, una para optimizar tiempo y otra para memoria y los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20072ce5-dabb-4e4f-a67f-ca9b2deddd20",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f818038-ca04-43d6-8789-fc444a1d34b1",
   "metadata": {},
   "source": [
    "Ejecutar esta linea de codigo sin comentar (borrar #) solamente una vez al inicio de la sesión para instalar el package de emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b800e092-5062-49c0-8813-5f87321a2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850b83e7-5d24-438a-93e1-4fae2549f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, to_date, col, desc, row_number, udf, explode\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from typing import List, Tuple\n",
    "import datetime\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c100673-b965-4719-a453-0204762b77b0",
   "metadata": {},
   "source": [
    "### Definición de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7544a191-c2c1-4488-8f6a-5bd24931e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680bf4b-5966-44fa-98fc-3da1a0ca6367",
   "metadata": {},
   "source": [
    "Definir una función que genera la session de Spark u obtiene una versión ya existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3a88b5-3ad8-4786-a9b4-0637d0bb8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_session() -> SparkSession:\n",
    "    return (SparkSession.builder\n",
    "            .appName(\"TwitterAnalysis\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faeff88-8ccc-4c23-8c7e-d5d9d754935e",
   "metadata": {},
   "source": [
    "## Problema 1\n",
    "Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene\n",
    "por cada uno de esos días. Debe incluir las siguientes funciones:\n",
    "- def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "- def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fdb8a-1807-4f7b-b339-7adf100c17ad",
   "metadata": {},
   "source": [
    "### Solución q1_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdec7df4-9fe4-4619-aed2-5baeb6122620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    spark = get_spark_session()\n",
    "\n",
    "    date_format = \"yyyy-MM-dd'T'HH:mm:ssXXX\"\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"date\", \"user.username\")\n",
    "                       .withColumn(\"date\", to_date(col(\"date\"), date_format))\n",
    "               )\n",
    "\n",
    "    top_dates_df = (tweetsDF.groupBy(\"date\")\n",
    "                           .agg(count(\"*\").alias(\"count\"))\n",
    "                           .orderBy(desc(\"count\"))\n",
    "                           .limit(10)\n",
    "                   )\n",
    "\n",
    "\n",
    "    top_dates_set = {row['date'] for row in top_dates_df.collect()}\n",
    "    filtered_df = tweetsDF.filter(col(\"date\").isin(top_dates_set))\n",
    "\n",
    "    grouped_df = (filtered_df.groupBy(\"date\", \"username\")\n",
    "                             .agg(count(\"*\").alias(\"count\"))\n",
    "                  )\n",
    "\n",
    "    windowSpec = Window.partitionBy(\"date\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    top_user_df = (grouped_df.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "                          .filter(col(\"row_number\") == 1)\n",
    "                          .drop(\"row_number\")\n",
    "                  )\n",
    "    top_user_df = top_user_df.withColumnRenamed(\"count\", \"tweets_by_user\")\n",
    "    \n",
    "    top_dates_with_users = (top_user_df.join(top_dates_df, \"date\")\n",
    "                                   .orderBy(desc(\"count\"), \"date\")\n",
    "                           )\n",
    "\n",
    "    return [(row['date'], row['username']) for row in top_dates_with_users.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbdffb-63f8-4d7a-adbe-6d2e7bcbafe3",
   "metadata": {},
   "source": [
    "Presentación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db2a023-a2a3-479a-8e4d-3d5f05e35cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- memory -------\n",
      "(datetime.date(2021, 2, 12), 'RanbirS00614606')\n",
      "(datetime.date(2021, 2, 13), 'MaanDee08215437')\n",
      "(datetime.date(2021, 2, 17), 'RaaJVinderkaur')\n",
      "(datetime.date(2021, 2, 16), 'jot__b')\n",
      "(datetime.date(2021, 2, 14), 'rebelpacifist')\n",
      "(datetime.date(2021, 2, 18), 'neetuanjle_nitu')\n",
      "(datetime.date(2021, 2, 15), 'jot__b')\n",
      "(datetime.date(2021, 2, 20), 'MangalJ23056160')\n",
      "(datetime.date(2021, 2, 23), 'Surrypuria')\n",
      "(datetime.date(2021, 2, 19), 'Preetm91')\n"
     ]
    }
   ],
   "source": [
    "print(\"----- memory -------\")\n",
    "q1_memory_result = q1_memory(file_path)\n",
    "for e in q1_memory_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89495bb-763a-41de-a903-1c4fb3236a72",
   "metadata": {},
   "source": [
    "### Solución q1_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8dedb0-c1e2-4b0f-8d5a-8ac1402547cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    spark = get_spark_session()\n",
    "\n",
    "    date_format = \"yyyy-MM-dd'T'HH:mm:ssXXX\"\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"date\", \"user.username\")\n",
    "                       .withColumn(\"date\", to_date(col(\"date\"), date_format))\n",
    "               ).cache()  # Cache tweetsDF as it is used in multiple operations\n",
    "\n",
    "    top_dates_df = (tweetsDF.groupBy(\"date\")\n",
    "                           .agg(count(\"*\").alias(\"count\"))\n",
    "                           .orderBy(desc(\"count\"))\n",
    "                           .limit(10)\n",
    "                   ).cache()  # Cache top_dates_df as it is used in multiple operations\n",
    "\n",
    "    # Use broadcast join for smaller DataFrame to speed up join operation\n",
    "    filtered_df = tweetsDF.join(F.broadcast(top_dates_df), \"date\")\n",
    "\n",
    "    grouped_df = (filtered_df.groupBy(\"date\", \"username\")\n",
    "                             .agg(count(\"*\").alias(\"count\"))\n",
    "                  ).cache()  # Cache grouped_df as it is used in multiple operations\n",
    "\n",
    "    windowSpec = Window.partitionBy(\"date\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    top_user_df = (grouped_df.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "                          .filter(col(\"row_number\") == 1)\n",
    "                          .drop(\"row_number\")\n",
    "                  ).withColumnRenamed(\"count\", \"tweets_by_user\")\n",
    "    \n",
    "    top_dates_with_users = (top_user_df.join(top_dates_df, \"date\")\n",
    "                                   .orderBy(desc(\"count\"), \"date\")\n",
    "                           )\n",
    "\n",
    "    return [(row['date'], row['username']) for row in top_dates_with_users.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02bdc705-0d30-4d9c-a07c-569c9b8ebcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- time -------\n",
      "(datetime.date(2021, 2, 12), 'RanbirS00614606')\n",
      "(datetime.date(2021, 2, 13), 'MaanDee08215437')\n",
      "(datetime.date(2021, 2, 17), 'RaaJVinderkaur')\n",
      "(datetime.date(2021, 2, 16), 'jot__b')\n",
      "(datetime.date(2021, 2, 14), 'rebelpacifist')\n",
      "(datetime.date(2021, 2, 18), 'neetuanjle_nitu')\n",
      "(datetime.date(2021, 2, 15), 'jot__b')\n",
      "(datetime.date(2021, 2, 20), 'MangalJ23056160')\n",
      "(datetime.date(2021, 2, 23), 'Surrypuria')\n",
      "(datetime.date(2021, 2, 19), 'Preetm91')\n"
     ]
    }
   ],
   "source": [
    "print(\"----- time -------\")\n",
    "q1_time_result = q1_time(file_path)\n",
    "for e in q1_time_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9570f-444d-46f1-a169-d43819890630",
   "metadata": {},
   "source": [
    "## Problema 2\n",
    "Los top 10 emojis más usados con su respectivo conteo. Debe incluir las siguientes funciones:\n",
    "- def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "- def q2_memory(file_path: str) -> List[Tuple[str, int]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58dc1e9-2d9b-4955-8991-684536c0a17b",
   "metadata": {},
   "source": [
    "### Solución q2_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc67324-e31a-473f-acc7-17bc4d53a0e0",
   "metadata": {},
   "source": [
    "Definir una función que extrae todos los emojis usando el paquete de emoji (instalado al incio del notebook) emoji.emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16012f0e-191a-447a-8e1b-caad069c2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(text):\n",
    "    return [char['emoji'] for char in emoji.emoji_list(text)]\n",
    "\n",
    "# Registrar la función como una UDF\n",
    "extract_emojis_udf = udf(extract_emojis, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6078e8a-dc36-4219-8a14-d902d369fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_general(file_path: str) -> List[Tuple[str, int]]:\n",
    "    spark = get_spark_session()\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\"))\n",
    "   \n",
    "    # Usar la UDF para extraer emojis y crear una nueva columna en el DataFrame\n",
    "    tweets_with_emojis_df = tweetsDF.withColumn(\"emojis\", extract_emojis_udf(tweetsDF[\"content\"]))\n",
    "\n",
    "    df_only_emojis = tweets_with_emojis_df.filter(\"size(emojis) > 0\")\n",
    "\n",
    "    # Mostrar resultados\n",
    "    #tweets_with_emojis_df.select(\"emojis\", \"content\").show(truncate=False)\n",
    "    #df_only_emojis.select(\"emojis\").show(truncate=False)\n",
    "\n",
    "    top_emojis = (df_only_emojis.select(explode(\"emojis\").alias(\"emoji\"))\n",
    "              .groupBy(\"emoji\")\n",
    "              .agg(count(\"*\").alias(\"count\"))\n",
    "              .orderBy(desc(\"count\"))\n",
    "              .limit(10))\n",
    "    #top_emojis.show(truncate=False)\n",
    "    return [(row['emoji'], row['count']) for row in top_emojis.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47f148-2aaf-4967-a32d-ee4f5d7bdd80",
   "metadata": {},
   "source": [
    "Presentación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84334572-5657-47cb-80b3-eee410caccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_general_result = q2_general(file_path)\n",
    "for e in q2_general_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a60c42-cdc7-41bd-a1f3-6862de0f6e1e",
   "metadata": {},
   "source": [
    "## Problema 3\n",
    "El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@)\n",
    "que registra cada uno de ellos. Debe incluir las siguientes funciones:\n",
    "  - def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "  - def q3_memory(file_path: str) -> List[Tuple[str, int]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d2652-4c15-4489-85b4-c8c0c1a9eb7e",
   "metadata": {},
   "source": [
    "###  Solución q3_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d333f-f540-4a75-a2ea-d35719c6e1c8",
   "metadata": {},
   "source": [
    "Definir una función que extrae menciones usando expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af8ba9-8772-491a-a7f2-f78741513f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mentions(text):\n",
    "    return re.findall(r\"@\\w+\", text)\n",
    "\n",
    "# Registrar la función como una UDF\n",
    "extract_mentions_udf = udf(extract_mentions, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25835adb-c716-42e7-95ec-4fb35dfd528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_general(file_path: str) -> List[Tuple[str, int]]: \n",
    "    spark = get_spark_session()\n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\"))\n",
    "\n",
    "    # Usar la UDF para extraer menciones y crear una nueva columna en el DataFrame\n",
    "    df_with_mentions = tweetsDF.withColumn(\"mentions\", extract_mentions_udf(tweetsDF[\"content\"]))\n",
    "    \n",
    "    # Crear una nueva fila para cada mención usando explode y contar las ocurrencias de cada mención\n",
    "    top_mentions = (df_with_mentions.select(explode(\"mentions\").alias(\"mention\"))\n",
    "                    .groupBy(\"mention\")\n",
    "                    .agg(count(\"*\").alias(\"count\"))\n",
    "                    .orderBy(desc(\"count\"))\n",
    "                    .limit(10))\n",
    "    \n",
    "    return [(row['mention'], row['count']) for row in top_mentions.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a7fd9b-f592-4fb9-a79d-96e6fdddd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_general_result = q3_general(file_path)\n",
    "for e in q3_general_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ced63-d181-413d-8b62-9fa298bd5ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

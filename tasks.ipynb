{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee82243c-fcbb-4cf8-bbc0-fae7eab78224",
   "metadata": {},
   "source": [
    "# Challenge Data Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b29ba-6c1e-471e-a20b-2b31b77bfdf6",
   "metadata": {},
   "source": [
    "Este Notebook contiene las soluciones para resolver tres problemas usando la libreria de pyspark, consta de 4 secciones:\n",
    "- InicializaciÃ³n, en donde se importa las librerias, constantes y funciones que se usan en el resto del cÃ³digo\n",
    "- Una secciÃ³n por cada uno de los tres problemas del reto. Cada soluciÃ³n contiene la descripciÃ³n, las soluciones con dos versiones, una para optimizar tiempo y otra para memoria y los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20072ce5-dabb-4e4f-a67f-ca9b2deddd20",
   "metadata": {},
   "source": [
    "## InicializaciÃ³n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f818038-ca04-43d6-8789-fc444a1d34b1",
   "metadata": {},
   "source": [
    "Ejecutar esta linea de codigo sin comentar (borrar #) solamente una vez al inicio de la sesiÃ³n para instalar el package de emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b800e092-5062-49c0-8813-5f87321a2545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.11/site-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850b83e7-5d24-438a-93e1-4fae2549f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, to_date, col, desc, row_number, udf, explode\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from typing import List, Tuple\n",
    "import datetime\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c100673-b965-4719-a453-0204762b77b0",
   "metadata": {},
   "source": [
    "### DefiniciÃ³n de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7544a191-c2c1-4488-8f6a-5bd24931e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680bf4b-5966-44fa-98fc-3da1a0ca6367",
   "metadata": {},
   "source": [
    "Definir una funciÃ³n que genera la session de Spark u obtiene una versiÃ³n ya existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3a88b5-3ad8-4786-a9b4-0637d0bb8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_session() -> SparkSession:\n",
    "    return (SparkSession.builder\n",
    "            .appName(\"TwitterAnalysis\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faeff88-8ccc-4c23-8c7e-d5d9d754935e",
   "metadata": {},
   "source": [
    "## Problema 1\n",
    "Las top 10 fechas donde hay mÃ¡s tweets. Mencionar el usuario (username) que mÃ¡s publicaciones tiene\n",
    "por cada uno de esos dÃ­as. Debe incluir las siguientes funciones:\n",
    "- def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "- def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fdb8a-1807-4f7b-b339-7adf100c17ad",
   "metadata": {},
   "source": [
    "### SoluciÃ³n q1_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdec7df4-9fe4-4619-aed2-5baeb6122620",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    spark = get_spark_session()\n",
    "\n",
    "    date_format = \"yyyy-MM-dd'T'HH:mm:ssXXX\"\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"date\", \"user.username\")\n",
    "                       .withColumn(\"date\", to_date(col(\"date\"), date_format))\n",
    "               )\n",
    "\n",
    "    top_dates_df = (tweetsDF.groupBy(\"date\")\n",
    "                           .agg(count(\"*\").alias(\"count\"))\n",
    "                           .orderBy(desc(\"count\"))\n",
    "                           .limit(10)\n",
    "                   )\n",
    "\n",
    "\n",
    "    top_dates_set = {row['date'] for row in top_dates_df.collect()}\n",
    "    filtered_df = tweetsDF.filter(col(\"date\").isin(top_dates_set))\n",
    "\n",
    "    grouped_df = (filtered_df.groupBy(\"date\", \"username\")\n",
    "                             .agg(count(\"*\").alias(\"count\"))\n",
    "                  )\n",
    "\n",
    "    windowSpec = Window.partitionBy(\"date\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    top_user_df = (grouped_df.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "                          .filter(col(\"row_number\") == 1)\n",
    "                          .drop(\"row_number\")\n",
    "                  )\n",
    "    top_user_df = top_user_df.withColumnRenamed(\"count\", \"tweets_by_user\")\n",
    "    \n",
    "    top_dates_with_users = (top_user_df.join(top_dates_df, \"date\")\n",
    "                                   .orderBy(desc(\"count\"), \"date\")\n",
    "                           )\n",
    "\n",
    "    return [(row['date'], row['username']) for row in top_dates_with_users.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbdffb-63f8-4d7a-adbe-6d2e7bcbafe3",
   "metadata": {},
   "source": [
    "PresentaciÃ³n de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db2a023-a2a3-479a-8e4d-3d5f05e35cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- memory -------\n",
      "(datetime.date(2021, 2, 12), 'RanbirS00614606')\n",
      "(datetime.date(2021, 2, 13), 'MaanDee08215437')\n",
      "(datetime.date(2021, 2, 17), 'RaaJVinderkaur')\n",
      "(datetime.date(2021, 2, 16), 'jot__b')\n",
      "(datetime.date(2021, 2, 14), 'rebelpacifist')\n",
      "(datetime.date(2021, 2, 18), 'neetuanjle_nitu')\n",
      "(datetime.date(2021, 2, 15), 'jot__b')\n",
      "(datetime.date(2021, 2, 20), 'MangalJ23056160')\n",
      "(datetime.date(2021, 2, 23), 'Surrypuria')\n",
      "(datetime.date(2021, 2, 19), 'Preetm91')\n"
     ]
    }
   ],
   "source": [
    "print(\"----- memory -------\")\n",
    "q1_memory_result = q1_memory(file_path)\n",
    "for e in q1_memory_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89495bb-763a-41de-a903-1c4fb3236a72",
   "metadata": {},
   "source": [
    "### SoluciÃ³n q1_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8dedb0-c1e2-4b0f-8d5a-8ac1402547cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    spark = get_spark_session()\n",
    "\n",
    "    date_format = \"yyyy-MM-dd'T'HH:mm:ssXXX\"\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"date\", \"user.username\")\n",
    "                       .withColumn(\"date\", to_date(col(\"date\"), date_format))\n",
    "               ).cache()  # Cache tweetsDF as it is used in multiple operations\n",
    "\n",
    "    top_dates_df = (tweetsDF.groupBy(\"date\")\n",
    "                           .agg(count(\"*\").alias(\"count\"))\n",
    "                           .orderBy(desc(\"count\"))\n",
    "                           .limit(10)\n",
    "                   ).cache()  # Cache top_dates_df as it is used in multiple operations\n",
    "\n",
    "    # Use broadcast join for smaller DataFrame to speed up join operation\n",
    "    filtered_df = tweetsDF.join(F.broadcast(top_dates_df), \"date\")\n",
    "\n",
    "    grouped_df = (filtered_df.groupBy(\"date\", \"username\")\n",
    "                             .agg(count(\"*\").alias(\"count\"))\n",
    "                  ).cache()  # Cache grouped_df as it is used in multiple operations\n",
    "\n",
    "    windowSpec = Window.partitionBy(\"date\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    top_user_df = (grouped_df.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "                          .filter(col(\"row_number\") == 1)\n",
    "                          .drop(\"row_number\")\n",
    "                  ).withColumnRenamed(\"count\", \"tweets_by_user\")\n",
    "    \n",
    "    top_dates_with_users = (top_user_df.join(top_dates_df, \"date\")\n",
    "                                   .orderBy(desc(\"count\"), \"date\")\n",
    "                           )\n",
    "\n",
    "    return [(row['date'], row['username']) for row in top_dates_with_users.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02bdc705-0d30-4d9c-a07c-569c9b8ebcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- time -------\n",
      "(datetime.date(2021, 2, 12), 'RanbirS00614606')\n",
      "(datetime.date(2021, 2, 13), 'MaanDee08215437')\n",
      "(datetime.date(2021, 2, 17), 'RaaJVinderkaur')\n",
      "(datetime.date(2021, 2, 16), 'jot__b')\n",
      "(datetime.date(2021, 2, 14), 'rebelpacifist')\n",
      "(datetime.date(2021, 2, 18), 'neetuanjle_nitu')\n",
      "(datetime.date(2021, 2, 15), 'jot__b')\n",
      "(datetime.date(2021, 2, 20), 'MangalJ23056160')\n",
      "(datetime.date(2021, 2, 23), 'Surrypuria')\n",
      "(datetime.date(2021, 2, 19), 'Preetm91')\n"
     ]
    }
   ],
   "source": [
    "print(\"----- time -------\")\n",
    "q1_time_result = q1_time(file_path)\n",
    "for e in q1_time_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9570f-444d-46f1-a169-d43819890630",
   "metadata": {},
   "source": [
    "## Problema 2\n",
    "Los top 10 emojis mÃ¡s usados con su respectivo conteo. Debe incluir las siguientes funciones:\n",
    "- def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "- def q2_memory(file_path: str) -> List[Tuple[str, int]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58dc1e9-2d9b-4955-8991-684536c0a17b",
   "metadata": {},
   "source": [
    "### SoluciÃ³n q2_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc67324-e31a-473f-acc7-17bc4d53a0e0",
   "metadata": {},
   "source": [
    "Definir una funciÃ³n que extrae todos los emojis usando el paquete de emoji (instalado al incio del notebook) emoji.emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16012f0e-191a-447a-8e1b-caad069c2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(text):\n",
    "    return [char['emoji'] for char in emoji.emoji_list(text)]\n",
    "\n",
    "# Registrar la funciÃ³n como una UDF\n",
    "extract_emojis_udf = udf(extract_emojis, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "525b1ef8-f8e0-4a15-8078-94003070fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "        Se intenta hacer el menor numero de transformaciones posibles\n",
    "    \"\"\"\n",
    "    spark = get_spark_session()\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\", \"true\")\n",
    "                       .option(\"header\", \"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\"))\n",
    "   \n",
    "    tweets_with_emojis_df = tweetsDF.withColumn(\"emojis\", extract_emojis_udf(tweetsDF[\"content\"]))\n",
    "\n",
    "    # Directamente realizar operaciones en los datos sin almacenar en cachÃ©\n",
    "    top_emojis = (tweets_with_emojis_df.filter(F.size(\"emojis\") > 0)\n",
    "                                         .select(F.explode(\"emojis\").alias(\"emoji\"))\n",
    "                                         .groupBy(\"emoji\")\n",
    "                                         .agg(F.count(\"*\").alias(\"count\"))\n",
    "                                         .orderBy(F.desc(\"count\"))\n",
    "                                         .limit(10))\n",
    "\n",
    "    return [(row['emoji'], row['count']) for row in top_emojis.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e80f2944-ef11-48e2-8bdf-786101d9d88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ğŸ™', 5049)\n",
      "('ğŸ˜‚', 3072)\n",
      "('ğŸšœ', 2972)\n",
      "('ğŸŒ¾', 2182)\n",
      "('ğŸ‡®ğŸ‡³', 2086)\n",
      "('ğŸ¤£', 1668)\n",
      "('âœŠ', 1651)\n",
      "('â¤ï¸', 1382)\n",
      "('ğŸ™ğŸ»', 1317)\n",
      "('ğŸ’š', 1040)\n"
     ]
    }
   ],
   "source": [
    "q2_mem_result = q2_memory(file_path)\n",
    "for e in q2_mem_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47f148-2aaf-4967-a32d-ee4f5d7bdd80",
   "metadata": {},
   "source": [
    "PresentaciÃ³n de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed6c7b45-4a4f-4e5f-b492-45ac283b65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "        Para optimizar en velocidad se hace uso del cache\n",
    "    \"\"\"\n",
    "    spark = get_spark_session()\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\", \"true\")\n",
    "                       .option(\"header\", \"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\")\n",
    "               ).cache() #Se utiliza cache para almacenar en memoria\n",
    "    \n",
    "    tweets_with_emojis_df = tweetsDF.withColumn(\"emojis\", extract_emojis_udf(tweetsDF[\"content\"])).cache()\n",
    "   \n",
    "    df_only_emojis = tweets_with_emojis_df.filter(F.size(\"emojis\") > 0)\n",
    "\n",
    "    top_emojis = (df_only_emojis.select(F.explode(\"emojis\").alias(\"emoji\"))\n",
    "                                  .groupBy(\"emoji\")\n",
    "                                  .agg(F.count(\"*\").alias(\"count\"))\n",
    "                                  .orderBy(F.desc(\"count\"))\n",
    "                                  .limit(10))\n",
    "\n",
    "    return [(row['emoji'], row['count']) for row in top_emojis.collect()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a737dd0c-211a-4e5b-a840-a6eac8791e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ğŸ™', 5049)\n",
      "('ğŸ˜‚', 3072)\n",
      "('ğŸšœ', 2972)\n",
      "('ğŸŒ¾', 2182)\n",
      "('ğŸ‡®ğŸ‡³', 2086)\n",
      "('ğŸ¤£', 1668)\n",
      "('âœŠ', 1651)\n",
      "('â¤ï¸', 1382)\n",
      "('ğŸ™ğŸ»', 1317)\n",
      "('ğŸ’š', 1040)\n"
     ]
    }
   ],
   "source": [
    "q2_time_result = q2_time(file_path)\n",
    "for e in q2_time_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba9ef81-8f60-44be-8336-636021dad9b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

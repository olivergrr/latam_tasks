{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee82243c-fcbb-4cf8-bbc0-fae7eab78224",
   "metadata": {},
   "source": [
    "# Challenge Data Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b29ba-6c1e-471e-a20b-2b31b77bfdf6",
   "metadata": {},
   "source": [
    "Este Notebook contiene las soluciones para resolver tres problemas usando la libreria de pyspark, consta de 4 secciones:\n",
    "- Inicialización, en donde se importa las librerias, constantes y funciones que se usan en el resto del código\n",
    "- Una sección por cada uno de los tres problemas del reto. Cada solución contiene la descripción, las soluciones con dos versiones, una para optimizar tiempo y otra para memoria y los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20072ce5-dabb-4e4f-a67f-ca9b2deddd20",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f818038-ca04-43d6-8789-fc444a1d34b1",
   "metadata": {},
   "source": [
    "Ejecutar esta linea de codigo sin comentar solamente una vez al inicio de la sesión para instalar el package de emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b800e092-5062-49c0-8813-5f87321a2545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/96/c6/0114b2040a96561fd1b44c75df749bbd3c898bf8047fb5ce8d7590d2dee6/emoji-2.8.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.8.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji  #API reference: https://carpedm20.github.io/emoji/docs/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850b83e7-5d24-438a-93e1-4fae2549f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, to_date, col, desc, row_number, udf, explode\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from typing import List, Tuple\n",
    "import datetime\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c100673-b965-4719-a453-0204762b77b0",
   "metadata": {},
   "source": [
    "### Definición de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7544a191-c2c1-4488-8f6a-5bd24931e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680bf4b-5966-44fa-98fc-3da1a0ca6367",
   "metadata": {},
   "source": [
    "Definir una función que genera la session de Spark u obtiene una versión ya existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3a88b5-3ad8-4786-a9b4-0637d0bb8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_session() -> SparkSession:\n",
    "    return (SparkSession.builder\n",
    "            .appName(\"TwitterAnalysis\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faeff88-8ccc-4c23-8c7e-d5d9d754935e",
   "metadata": {},
   "source": [
    "## Problema 1\n",
    "Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene\n",
    "por cada uno de esos días. Debe incluir las siguientes funciones:\n",
    "- def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "- def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89495bb-763a-41de-a903-1c4fb3236a72",
   "metadata": {},
   "source": [
    "### Solución q1_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f8dedb0-c1e2-4b0f-8d5a-8ac1402547cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "        Funcion para la optimizacion basada en tiempo, aqui se hace uso de cache para cada uno de los DataFrames\n",
    "        intermedios aunque el uso de memoria es mas extensivo, ademas se utiliza broadcast join para mejorar la\n",
    "        eficiencia en red y la paralelizacion en los nodos\n",
    "    \"\"\"\n",
    "    \n",
    "    spark = get_spark_session()\n",
    "\n",
    "    date_format = \"yyyy-MM-dd'T'HH:mm:ssXXX\"\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"date\", \"user.username\")\n",
    "                       .withColumn(\"date\", to_date(col(\"date\"), date_format))\n",
    "               ).cache()  # Cache tweetsDF debido a que es usado multiples veces\n",
    "\n",
    "    top_dates_df = (tweetsDF.groupBy(\"date\")\n",
    "                           .agg(count(\"*\").alias(\"count\"))\n",
    "                           .orderBy(desc(\"count\"))\n",
    "                           .limit(10)\n",
    "                   ).cache()  # Cache top_dates_df debido a que es usado multiples veces\n",
    "\n",
    "    # Se usa broadcast join ya que es un conjunto pequeño de fechas para acelerar la operación de join, \n",
    "    filtered_df = tweetsDF.join(F.broadcast(top_dates_df), \"date\")\n",
    "\n",
    "    grouped_df = (filtered_df.groupBy(\"date\", \"username\")\n",
    "                             .agg(count(\"*\").alias(\"count\"))\n",
    "                  ).cache()  # Cache grouped_df debido a que es usado multiples veces\n",
    "\n",
    "    windowSpec = Window.partitionBy(\"date\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    top_user_df = (grouped_df.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "                          .filter(col(\"row_number\") == 1)\n",
    "                          .drop(\"row_number\")\n",
    "                  ).withColumnRenamed(\"count\", \"tweets_by_user\")\n",
    "    \n",
    "    top_dates_with_users = (top_user_df.join(top_dates_df, \"date\")\n",
    "                                   .orderBy(desc(\"count\"), \"date\")\n",
    "                            .collect()\n",
    "                           )\n",
    "\n",
    "    return [(row['date'], row['username']) for row in top_dates_with_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "02bdc705-0d30-4d9c-a07c-569c9b8ebcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- time -------\n",
      "(datetime.date(2021, 2, 12), 'RanbirS00614606')\n",
      "(datetime.date(2021, 2, 13), 'MaanDee08215437')\n",
      "(datetime.date(2021, 2, 17), 'RaaJVinderkaur')\n",
      "(datetime.date(2021, 2, 16), 'jot__b')\n",
      "(datetime.date(2021, 2, 14), 'rebelpacifist')\n",
      "(datetime.date(2021, 2, 18), 'neetuanjle_nitu')\n",
      "(datetime.date(2021, 2, 15), 'jot__b')\n",
      "(datetime.date(2021, 2, 20), 'MangalJ23056160')\n",
      "(datetime.date(2021, 2, 23), 'Surrypuria')\n",
      "(datetime.date(2021, 2, 19), 'Preetm91')\n"
     ]
    }
   ],
   "source": [
    "print(\"----- time -------\")\n",
    "q1_time_result = q1_time(file_path)\n",
    "for e in q1_time_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fdb8a-1807-4f7b-b339-7adf100c17ad",
   "metadata": {},
   "source": [
    "### Solución q1_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdec7df4-9fe4-4619-aed2-5baeb6122620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "        Funcion para la optimizacion basada en memoria, se utilizan utiliza la menor cantidad\n",
    "        de transformaciones necesarias, para evitar el uso excesivo de memoria\n",
    "    \"\"\"\n",
    "    spark = get_spark_session()\n",
    "\n",
    "    date_format = \"yyyy-MM-dd'T'HH:mm:ssXXX\"\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\", \"true\")\n",
    "                       .option(\"header\", \"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"date\", \"user.username\")\n",
    "                       .withColumn(\"date\", to_date(col(\"date\"), date_format))\n",
    "               )\n",
    "\n",
    "    # Calcular el numero de tweets por usuario\n",
    "    grouped_df = (tweetsDF.groupBy(\"date\", \"username\")\n",
    "                          .agg(count(\"*\").alias(\"count\"))\n",
    "                 )\n",
    "\n",
    "    # se definen funciones de ventana para obtener el top de fechas y el usuario con mas tweets\n",
    "    windowSpecDates = Window.orderBy(desc(\"count_dates\"))\n",
    "    windowSpecUsers = Window.partitionBy(\"date\").orderBy(desc(\"count\"))\n",
    "\n",
    "    # Calcular el top 10 de fechas y el top 1 de usuarios usando las funciones de ventana en una sola operacion\n",
    "    result = (grouped_df.groupBy(\"date\")\n",
    "                      .agg(F.sum(\"count\").alias(\"count_dates\"))\n",
    "                      .withColumn(\"rank_dates\", row_number().over(windowSpecDates))\n",
    "                      .filter(col(\"rank_dates\") <= 10)\n",
    "                      .join(grouped_df, \"date\")\n",
    "                      .withColumn(\"rank_users\", row_number().over(windowSpecUsers))\n",
    "                      .filter(col(\"rank_users\") == 1)\n",
    "                      .orderBy(desc(\"count_dates\"), \"date\")\n",
    "                      .select(\"date\", \"username\")\n",
    "                      .collect()\n",
    "              )\n",
    "\n",
    "    return [(row['date'], row['username']) for row in result]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbdffb-63f8-4d7a-adbe-6d2e7bcbafe3",
   "metadata": {},
   "source": [
    "Presentación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9db2a023-a2a3-479a-8e4d-3d5f05e35cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- memory -------\n",
      "(datetime.date(2021, 2, 12), 'RanbirS00614606')\n",
      "(datetime.date(2021, 2, 13), 'MaanDee08215437')\n",
      "(datetime.date(2021, 2, 17), 'RaaJVinderkaur')\n",
      "(datetime.date(2021, 2, 16), 'jot__b')\n",
      "(datetime.date(2021, 2, 14), 'rebelpacifist')\n",
      "(datetime.date(2021, 2, 18), 'neetuanjle_nitu')\n",
      "(datetime.date(2021, 2, 15), 'jot__b')\n",
      "(datetime.date(2021, 2, 20), 'MangalJ23056160')\n",
      "(datetime.date(2021, 2, 23), 'Surrypuria')\n",
      "(datetime.date(2021, 2, 19), 'Preetm91')\n"
     ]
    }
   ],
   "source": [
    "print(\"----- memory -------\")\n",
    "q1_memory_result = q1_memory(file_path)\n",
    "for e in q1_memory_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9570f-444d-46f1-a169-d43819890630",
   "metadata": {},
   "source": [
    "## Problema 2\n",
    "Los top 10 emojis más usados con su respectivo conteo. Debe incluir las siguientes funciones:\n",
    "- def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "- def q2_memory(file_path: str) -> List[Tuple[str, int]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58dc1e9-2d9b-4955-8991-684536c0a17b",
   "metadata": {},
   "source": [
    "### Solución q2_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc67324-e31a-473f-acc7-17bc4d53a0e0",
   "metadata": {},
   "source": [
    "Definir una función que extrae todos los emojis usando el paquete de emoji (instalado al incio del notebook) emoji.emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16012f0e-191a-447a-8e1b-caad069c2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(text):\n",
    "    return [char['emoji'] for char in emoji.emoji_list(text)]\n",
    "\n",
    "# Registrar la función como una UDF\n",
    "extract_emojis_udf = udf(extract_emojis, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed6c7b45-4a4f-4e5f-b492-45ac283b65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "        Funcion para la optimizacion basada en tiempo, Para optimizar en velocidad se hace uso del cache\n",
    "    \"\"\"\n",
    "    spark = get_spark_session()\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\", \"true\")\n",
    "                       .option(\"header\", \"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\")\n",
    "               ).cache() #Se utiliza cache para almacenar en memoria\n",
    "    \n",
    "    tweets_with_emojis_df = tweetsDF.withColumn(\"emojis\", extract_emojis_udf(tweetsDF[\"content\"])).cache()\n",
    "   \n",
    "    df_only_emojis = tweets_with_emojis_df.filter(F.size(\"emojis\") > 0)\n",
    "\n",
    "    top_emojis = (df_only_emojis.select(F.explode(\"emojis\").alias(\"emoji\"))\n",
    "                                  .groupBy(\"emoji\")\n",
    "                                  .agg(F.count(\"*\").alias(\"count\"))\n",
    "                                  .orderBy(F.desc(\"count\"))\n",
    "                                  .limit(10))\n",
    "\n",
    "    return [(row['emoji'], row['count']) for row in top_emojis.collect()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47f148-2aaf-4967-a32d-ee4f5d7bdd80",
   "metadata": {},
   "source": [
    "Presentación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a737dd0c-211a-4e5b-a840-a6eac8791e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('🙏', 5049)\n",
      "('😂', 3072)\n",
      "('🚜', 2972)\n",
      "('🌾', 2182)\n",
      "('🇮🇳', 2086)\n",
      "('🤣', 1668)\n",
      "('✊', 1651)\n",
      "('❤️', 1382)\n",
      "('🙏🏻', 1317)\n",
      "('💚', 1040)\n"
     ]
    }
   ],
   "source": [
    "q2_time_result = q2_time(file_path)\n",
    "for e in q2_time_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583efc37-63c8-4604-a69f-68d9cf0ac780",
   "metadata": {},
   "source": [
    "### Solución q2_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bbe0cf-b1d3-4138-b2e4-9cb9b7827826",
   "metadata": {},
   "source": [
    "Nota: Tambien se debe implementar la función de extract_emojis descrita anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "525b1ef8-f8e0-4a15-8078-94003070fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "        Funcion para la optimizacion basada en memoria. Se intenta hacer el menor numero de transformaciones posibles\n",
    "    \"\"\"\n",
    "    spark = get_spark_session()\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\", \"true\")\n",
    "                       .option(\"header\", \"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\"))\n",
    "   \n",
    "    tweets_with_emojis_df = tweetsDF.withColumn(\"emojis\", extract_emojis_udf(tweetsDF[\"content\"]))\n",
    "\n",
    "    # Directamente realizar operaciones en los datos sin almacenar en caché\n",
    "    top_emojis = (tweets_with_emojis_df.filter(F.size(\"emojis\") > 0)\n",
    "                                         .select(F.explode(\"emojis\").alias(\"emoji\"))\n",
    "                                         .groupBy(\"emoji\")\n",
    "                                         .agg(F.count(\"*\").alias(\"count\"))\n",
    "                                         .orderBy(F.desc(\"count\"))\n",
    "                                         .limit(10))\n",
    "\n",
    "    return [(row['emoji'], row['count']) for row in top_emojis.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea977e1-dd95-4981-af91-2901ff0f948a",
   "metadata": {},
   "source": [
    "Presentación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e80f2944-ef11-48e2-8bdf-786101d9d88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('🙏', 5049)\n",
      "('😂', 3072)\n",
      "('🚜', 2972)\n",
      "('🌾', 2182)\n",
      "('🇮🇳', 2086)\n",
      "('🤣', 1668)\n",
      "('✊', 1651)\n",
      "('❤️', 1382)\n",
      "('🙏🏻', 1317)\n",
      "('💚', 1040)\n"
     ]
    }
   ],
   "source": [
    "q2_mem_result = q2_memory(file_path)\n",
    "for e in q2_mem_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a60c42-cdc7-41bd-a1f3-6862de0f6e1e",
   "metadata": {},
   "source": [
    "## Problema 3\n",
    "El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@)\n",
    "que registra cada uno de ellos. Debe incluir las siguientes funciones:\n",
    "  - def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "  - def q3_memory(file_path: str) -> List[Tuple[str, int]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d2652-4c15-4489-85b4-c8c0c1a9eb7e",
   "metadata": {},
   "source": [
    "###  Solución q3_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d333f-f540-4a75-a2ea-d35719c6e1c8",
   "metadata": {},
   "source": [
    "Definir una función que extrae menciones usando expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61af8ba9-8772-491a-a7f2-f78741513f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mentions(text):\n",
    "    return re.findall(r\"@\\w+\", text)\n",
    "\n",
    "# Registrar la función como una UDF\n",
    "extract_mentions_udf = udf(extract_mentions, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "293ced63-d181-413d-8b62-9fa298bd5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "        Para optimizar en velocidad se hace uso del cache\n",
    "    \"\"\"\n",
    "    spark = get_spark_session()\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\", \"true\")\n",
    "                       .option(\"header\", \"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\")).cache()\n",
    "    \n",
    "    df_with_mentions = tweetsDF.withColumn(\"mentions\", extract_mentions_udf(tweetsDF[\"content\"])).cache()\n",
    "   \n",
    "    top_mentions = (df_with_mentions.select(F.explode(\"mentions\").alias(\"mention\"))\n",
    "                                    .groupBy(\"mention\")\n",
    "                                    .agg(F.count(\"*\").alias(\"count\"))\n",
    "                                    .orderBy(F.desc(\"count\"))\n",
    "                                    .limit(10))\n",
    "    \n",
    "    return [(row['mention'], row['count']) for row in top_mentions.collect()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437433aa-411c-4bd9-8292-24357b4ddca6",
   "metadata": {},
   "source": [
    "Presentación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81a7fd9b-f592-4fb9-a79d-96e6fdddd1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('@narendramodi', 2261)\n",
      "('@Kisanektamorcha', 1836)\n",
      "('@RakeshTikaitBKU', 1639)\n",
      "('@PMOIndia', 1422)\n",
      "('@RahulGandhi', 1125)\n",
      "('@GretaThunberg', 1046)\n",
      "('@RaviSinghKA', 1015)\n",
      "('@rihanna', 972)\n",
      "('@UNHumanRights', 962)\n",
      "('@meenaharris', 925)\n"
     ]
    }
   ],
   "source": [
    "q3_time_result = q3_time(file_path)\n",
    "for e in q3_time_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce3510-53fe-47d1-9868-3e2030b29bf1",
   "metadata": {},
   "source": [
    "###  Solución q3_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4898f73-1732-4b41-a76c-a1efbe9f186d",
   "metadata": {},
   "source": [
    "Nota: Tambien se debe implementar la función de extrac_mentions descrita anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46f73d99-3185-4df2-b7cd-88ad62d75959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "        Para optimizar en memoria se evita el uso del cache\n",
    "    \"\"\"\n",
    "    spark = get_spark_session()\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\", \"true\")\n",
    "                       .option(\"header\", \"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\"))\n",
    "    \n",
    "    df_with_mentions = tweetsDF.withColumn(\"mentions\", extract_mentions_udf(tweetsDF[\"content\"]))\n",
    "\n",
    "    # Directamente realizar operaciones en los datos sin almacenar en caché\n",
    "    top_mentions = (df_with_mentions.select(F.explode(\"mentions\").alias(\"mention\"))\n",
    "                                    .groupBy(\"mention\")\n",
    "                                    .agg(F.count(\"*\").alias(\"count\"))\n",
    "                                    .orderBy(F.desc(\"count\"))\n",
    "                                    .limit(10))\n",
    "    \n",
    "    return [(row['mention'], row['count']) for row in top_mentions.collect()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1abb2-9332-4ccb-88e5-9f2b027a5236",
   "metadata": {},
   "source": [
    "Presentación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7b7fe027-2d17-4778-a60a-d2ce1c233e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('@narendramodi', 2261)\n",
      "('@Kisanektamorcha', 1836)\n",
      "('@RakeshTikaitBKU', 1639)\n",
      "('@PMOIndia', 1422)\n",
      "('@RahulGandhi', 1125)\n",
      "('@GretaThunberg', 1046)\n",
      "('@RaviSinghKA', 1015)\n",
      "('@rihanna', 972)\n",
      "('@UNHumanRights', 962)\n",
      "('@meenaharris', 925)\n"
     ]
    }
   ],
   "source": [
    "q3_memory_result = q3_memory(file_path)\n",
    "for e in q3_memory_result:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

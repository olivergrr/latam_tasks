{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee82243c-fcbb-4cf8-bbc0-fae7eab78224",
   "metadata": {},
   "source": [
    "# Challenge Data Engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b29ba-6c1e-471e-a20b-2b31b77bfdf6",
   "metadata": {},
   "source": [
    "Este Notebook contiene las soluciones para resolver tres problemas usando la libreria de pyspark, consta de 4 secciones:\n",
    "- Inicialización, en donde se importa las librerias, constantes y funciones que se usan en el resto del código\n",
    "- Una sección por cada uno de los tres problemas del reto. Cada solución contiene la descripción, las soluciones con dos versiones, una para optimizar tiempo y otra para memoria y los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20072ce5-dabb-4e4f-a67f-ca9b2deddd20",
   "metadata": {},
   "source": [
    "## Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f818038-ca04-43d6-8789-fc444a1d34b1",
   "metadata": {},
   "source": [
    "Ejecutar esta linea de codigo sin comentar solamente una vez al inicio de la sesión para instalar el package de emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b800e092-5062-49c0-8813-5f87321a2545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/96/c6/0114b2040a96561fd1b44c75df749bbd3c898bf8047fb5ce8d7590d2dee6/emoji-2.8.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.8.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji  #API reference: https://carpedm20.github.io/emoji/docs/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850b83e7-5d24-438a-93e1-4fae2549f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, to_date, col, desc, row_number, udf, explode\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from typing import List, Tuple\n",
    "import datetime\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c100673-b965-4719-a453-0204762b77b0",
   "metadata": {},
   "source": [
    "### Definición de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7544a191-c2c1-4488-8f6a-5bd24931e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680bf4b-5966-44fa-98fc-3da1a0ca6367",
   "metadata": {},
   "source": [
    "Definir una función que genera la session de Spark u obtiene una versión ya existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e3a88b5-3ad8-4786-a9b4-0637d0bb8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_session() -> SparkSession:\n",
    "    return (SparkSession.builder\n",
    "            .appName(\"TwitterAnalysis\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faeff88-8ccc-4c23-8c7e-d5d9d754935e",
   "metadata": {},
   "source": [
    "## Problema 1\n",
    "Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene\n",
    "por cada uno de esos días. Debe incluir las siguientes funciones:\n",
    "- def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "- def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372fdb8a-1807-4f7b-b339-7adf100c17ad",
   "metadata": {},
   "source": [
    "### Solución q1_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdec7df4-9fe4-4619-aed2-5baeb6122620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "        Se utilizan utiliza la menos cantidad de transformaciones necesarias, para evitar el uso excesivo de memoria\n",
    "    \"\"\"\n",
    "    spark = get_spark_session()\n",
    "\n",
    "    date_format = \"yyyy-MM-dd'T'HH:mm:ssXXX\"\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\", \"true\")\n",
    "                       .option(\"header\", \"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"date\", \"user.username\")\n",
    "                       .withColumn(\"date\", to_date(col(\"date\"), date_format))\n",
    "               )\n",
    "\n",
    "    # Calcular el numero de tweets por usuario\n",
    "    grouped_df = (tweetsDF.groupBy(\"date\", \"username\")\n",
    "                          .agg(count(\"*\").alias(\"count\"))\n",
    "                 )\n",
    "\n",
    "    # se definen funciones de ventana para obtener el top de fechas y el usuario con mas tweets\n",
    "    windowSpecDates = Window.orderBy(desc(\"count_dates\"))\n",
    "    windowSpecUsers = Window.partitionBy(\"date\").orderBy(desc(\"count\"))\n",
    "\n",
    "    # Calcular el top 10 de fechas y el top 1 de usuarios usando las funciones de ventana en una sola operacion\n",
    "    result = (grouped_df.groupBy(\"date\")\n",
    "                      .agg(F.sum(\"count\").alias(\"count_dates\"))\n",
    "                      .withColumn(\"rank_dates\", row_number().over(windowSpecDates))\n",
    "                      .filter(col(\"rank_dates\") <= 10)\n",
    "                      .join(grouped_df, \"date\")\n",
    "                      .withColumn(\"rank_users\", row_number().over(windowSpecUsers))\n",
    "                      .filter(col(\"rank_users\") == 1)\n",
    "                      .orderBy(desc(\"count_dates\"), \"date\")\n",
    "                      .select(\"date\", \"username\")\n",
    "                      .collect()\n",
    "              )\n",
    "\n",
    "    return [(row['date'], row['username']) for row in result]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbdffb-63f8-4d7a-adbe-6d2e7bcbafe3",
   "metadata": {},
   "source": [
    "Presentación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9db2a023-a2a3-479a-8e4d-3d5f05e35cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- memory -------\n",
      "(datetime.date(2021, 2, 12), 'RanbirS00614606')\n",
      "(datetime.date(2021, 2, 13), 'MaanDee08215437')\n",
      "(datetime.date(2021, 2, 17), 'RaaJVinderkaur')\n",
      "(datetime.date(2021, 2, 16), 'jot__b')\n",
      "(datetime.date(2021, 2, 14), 'rebelpacifist')\n",
      "(datetime.date(2021, 2, 18), 'neetuanjle_nitu')\n",
      "(datetime.date(2021, 2, 15), 'jot__b')\n",
      "(datetime.date(2021, 2, 20), 'MangalJ23056160')\n",
      "(datetime.date(2021, 2, 23), 'Surrypuria')\n",
      "(datetime.date(2021, 2, 19), 'Preetm91')\n"
     ]
    }
   ],
   "source": [
    "print(\"----- memory -------\")\n",
    "q1_memory_result = q1_memory(file_path)\n",
    "for e in q1_memory_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89495bb-763a-41de-a903-1c4fb3236a72",
   "metadata": {},
   "source": [
    "### Solución q1_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f8dedb0-c1e2-4b0f-8d5a-8ac1402547cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "        Funcion para la optimizacion basada en tiempo, aqiio se hace uso de cache para cada uno de los DataFrames\n",
    "        intermedios aunque el uso de memoria es mas extensivo, ademas se utiliza broadcast join para mejorar la\n",
    "        eficiencia en red y la paralelizacion en los nodos\n",
    "    \"\"\"\n",
    "    \n",
    "    spark = get_spark_session()\n",
    "\n",
    "    date_format = \"yyyy-MM-dd'T'HH:mm:ssXXX\"\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"date\", \"user.username\")\n",
    "                       .withColumn(\"date\", to_date(col(\"date\"), date_format))\n",
    "               ).cache()  # Cache tweetsDF debido a que es usado multiples veces\n",
    "\n",
    "    top_dates_df = (tweetsDF.groupBy(\"date\")\n",
    "                           .agg(count(\"*\").alias(\"count\"))\n",
    "                           .orderBy(desc(\"count\"))\n",
    "                           .limit(10)\n",
    "                   ).cache()  # Cache top_dates_df debido a que es usado multiples veces\n",
    "\n",
    "    # Se usa broadcast join ya que es un conjunto pequeño de fechas para acelerar la operación de join, \n",
    "    filtered_df = tweetsDF.join(F.broadcast(top_dates_df), \"date\")\n",
    "\n",
    "    grouped_df = (filtered_df.groupBy(\"date\", \"username\")\n",
    "                             .agg(count(\"*\").alias(\"count\"))\n",
    "                  ).cache()  # Cache grouped_df debido a que es usado multiples veces\n",
    "\n",
    "    windowSpec = Window.partitionBy(\"date\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    top_user_df = (grouped_df.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "                          .filter(col(\"row_number\") == 1)\n",
    "                          .drop(\"row_number\")\n",
    "                  ).withColumnRenamed(\"count\", \"tweets_by_user\")\n",
    "    \n",
    "    top_dates_with_users = (top_user_df.join(top_dates_df, \"date\")\n",
    "                                   .orderBy(desc(\"count\"), \"date\")\n",
    "                            .collect()\n",
    "                           )\n",
    "\n",
    "    return [(row['date'], row['username']) for row in top_dates_with_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02bdc705-0d30-4d9c-a07c-569c9b8ebcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- time -------\n",
      "(datetime.date(2021, 2, 12), 'RanbirS00614606')\n",
      "(datetime.date(2021, 2, 13), 'MaanDee08215437')\n",
      "(datetime.date(2021, 2, 17), 'RaaJVinderkaur')\n",
      "(datetime.date(2021, 2, 16), 'jot__b')\n",
      "(datetime.date(2021, 2, 14), 'rebelpacifist')\n",
      "(datetime.date(2021, 2, 18), 'neetuanjle_nitu')\n",
      "(datetime.date(2021, 2, 15), 'jot__b')\n",
      "(datetime.date(2021, 2, 20), 'MangalJ23056160')\n",
      "(datetime.date(2021, 2, 23), 'Surrypuria')\n",
      "(datetime.date(2021, 2, 19), 'Preetm91')\n"
     ]
    }
   ],
   "source": [
    "print(\"----- time -------\")\n",
    "q1_time_result = q1_time(file_path)\n",
    "for e in q1_time_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9570f-444d-46f1-a169-d43819890630",
   "metadata": {},
   "source": [
    "## Problema 2\n",
    "Los top 10 emojis más usados con su respectivo conteo. Debe incluir las siguientes funciones:\n",
    "- def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "- def q2_memory(file_path: str) -> List[Tuple[str, int]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58dc1e9-2d9b-4955-8991-684536c0a17b",
   "metadata": {},
   "source": [
    "### Solución q2_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc67324-e31a-473f-acc7-17bc4d53a0e0",
   "metadata": {},
   "source": [
    "Definir una función que extrae todos los emojis usando el paquete de emoji (instalado al incio del notebook) emoji.emoji_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16012f0e-191a-447a-8e1b-caad069c2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(text):\n",
    "    return [char['emoji'] for char in emoji.emoji_list(text)]\n",
    "\n",
    "# Registrar la función como una UDF\n",
    "extract_emojis_udf = udf(extract_emojis, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6078e8a-dc36-4219-8a14-d902d369fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_general(file_path: str) -> List[Tuple[str, int]]:\n",
    "    spark = get_spark_session()\n",
    "    \n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\"))\n",
    "   \n",
    "    # Usar la UDF para extraer emojis y crear una nueva columna en el DataFrame\n",
    "    tweets_with_emojis_df = tweetsDF.withColumn(\"emojis\", extract_emojis_udf(tweetsDF[\"content\"]))\n",
    "\n",
    "    df_only_emojis = tweets_with_emojis_df.filter(\"size(emojis) > 0\")\n",
    "\n",
    "    # Mostrar resultados\n",
    "    #tweets_with_emojis_df.select(\"emojis\", \"content\").show(truncate=False)\n",
    "    #df_only_emojis.select(\"emojis\").show(truncate=False)\n",
    "\n",
    "    top_emojis = (df_only_emojis.select(explode(\"emojis\").alias(\"emoji\"))\n",
    "              .groupBy(\"emoji\")\n",
    "              .agg(count(\"*\").alias(\"count\"))\n",
    "              .orderBy(desc(\"count\"))\n",
    "              .limit(10))\n",
    "    #top_emojis.show(truncate=False)\n",
    "    return [(row['emoji'], row['count']) for row in top_emojis.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f47f148-2aaf-4967-a32d-ee4f5d7bdd80",
   "metadata": {},
   "source": [
    "Presentación de los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84334572-5657-47cb-80b3-eee410caccc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('🙏', 5049)\n",
      "('😂', 3072)\n",
      "('🚜', 2972)\n",
      "('🌾', 2182)\n",
      "('🇮🇳', 2086)\n",
      "('🤣', 1668)\n",
      "('✊', 1651)\n",
      "('❤️', 1382)\n",
      "('🙏🏻', 1317)\n",
      "('💚', 1040)\n"
     ]
    }
   ],
   "source": [
    "q2_general_result = q2_general(file_path)\n",
    "for e in q2_general_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a60c42-cdc7-41bd-a1f3-6862de0f6e1e",
   "metadata": {},
   "source": [
    "## Problema 3\n",
    "El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@)\n",
    "que registra cada uno de ellos. Debe incluir las siguientes funciones:\n",
    "  - def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "  - def q3_memory(file_path: str) -> List[Tuple[str, int]]:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d2652-4c15-4489-85b4-c8c0c1a9eb7e",
   "metadata": {},
   "source": [
    "###  Solución q3_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d333f-f540-4a75-a2ea-d35719c6e1c8",
   "metadata": {},
   "source": [
    "Definir una función que extrae menciones usando expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61af8ba9-8772-491a-a7f2-f78741513f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mentions(text):\n",
    "    return re.findall(r\"@\\w+\", text)\n",
    "\n",
    "# Registrar la función como una UDF\n",
    "extract_mentions_udf = udf(extract_mentions, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25835adb-c716-42e7-95ec-4fb35dfd528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_general(file_path: str) -> List[Tuple[str, int]]: \n",
    "    spark = get_spark_session()\n",
    "    tweetsDF = (spark.read.option(\"inferSchema\",\"true\")\n",
    "                       .option(\"header\",\"true\")\n",
    "                       .json(file_path)\n",
    "                       .select(\"content\"))\n",
    "\n",
    "    # Usar la UDF para extraer menciones y crear una nueva columna en el DataFrame\n",
    "    df_with_mentions = tweetsDF.withColumn(\"mentions\", extract_mentions_udf(tweetsDF[\"content\"]))\n",
    "    \n",
    "    # Crear una nueva fila para cada mención usando explode y contar las ocurrencias de cada mención\n",
    "    top_mentions = (df_with_mentions.select(explode(\"mentions\").alias(\"mention\"))\n",
    "                    .groupBy(\"mention\")\n",
    "                    .agg(count(\"*\").alias(\"count\"))\n",
    "                    .orderBy(desc(\"count\"))\n",
    "                    .limit(10))\n",
    "    \n",
    "    return [(row['mention'], row['count']) for row in top_mentions.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a7fd9b-f592-4fb9-a79d-96e6fdddd1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('@narendramodi', 2261)\n",
      "('@Kisanektamorcha', 1836)\n",
      "('@RakeshTikaitBKU', 1639)\n",
      "('@PMOIndia', 1422)\n",
      "('@RahulGandhi', 1125)\n",
      "('@GretaThunberg', 1046)\n",
      "('@RaviSinghKA', 1015)\n",
      "('@rihanna', 972)\n",
      "('@UNHumanRights', 962)\n",
      "('@meenaharris', 925)\n"
     ]
    }
   ],
   "source": [
    "q3_general_result = q3_general(file_path)\n",
    "for e in q3_general_result:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ced63-d181-413d-8b62-9fa298bd5ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
